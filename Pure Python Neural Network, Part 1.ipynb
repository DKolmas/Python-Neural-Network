{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note is the first one out of a few next notes desribing implementation and analysis of pure python neural network. The purpose to do this exercise was to grasp a hands on experience with implementation details as I am moving now to Tensor Flow (TF). TF is a great tool. However, it is good to understand basic concepts first. \n",
    "\n",
    "At the beggining I planned to prepare just one note but over time it became clear it would be way to much content to make it digestible even for very stuborn and motivated person.\n",
    "\n",
    "In this note I will describe:\n",
    " * my motivation for doing that exercise (you might find yourself in a similar position, perheaps)\n",
    " * architecture of neural network implemented in python\n",
    " * data samples used for learning and testing\n",
    " * two different approaches used in implementation of backrpoagation algorithm\n",
    " * three methods of weights initiaizations used in analysis\n",
    " \n",
    "In the next note I will focus on performance analysis of trained network. I will provide many figures and complement it with results discussion. Finnaly I will formulate my conclussions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While attending Udacity online course in 2017, **[Deep Learninig Foundation](https://eu.udacity.com/course/deep-learning-nanodegree-foundation--nd101)**, I could see a greate possibilities using Deep Learning (via TensorFlow) in different tasks: image recognition, automatic translator engine, ... These task involves complex network architectures: Convolutional Neural Networks (CNN), Recuent Neural Networks (RNN) (and some flavors of it), and my favorit General Adversial Netowkrs (GANs). \n",
    "\n",
    "This course was great. It showed me how to build quickly powerfool tools using Tensor Flow to do very complex task. It was very motivating course and acutally it further encoured me to do more. I left the course with TensorFlow hands on experience and good overview of what deep learing can do for me.\n",
    "\n",
    "Also in my professional life I use Reinforced Learning where Neural Netowork is part of the whole framework. \n",
    "\n",
    "All of the above is more about applications of deep networks. At some point I decided to hold on for a \"moment\" and spent time to uderstand better theoretical aspects. And that is why I have created the note on pure python neural network.\n",
    "\n",
    "So far I can see already benefits of investing my time in this work. I can better understand NN related content I read therefore spending less time on digesting them (for eample nice explanation on [softmax in TensorFlow](https://stackoverflow.com/questions/34240703/whats-the-difference-between-softmax-and-softmax-cross-entropy-with-logits)). I can also further expand my knowledge. Shortly I plan to focus on understanding a concept of **Actor-Critic Algorithms**.\n",
    "\n",
    "So far I have also created other notes on:\n",
    " * [Foundation of backpropagation algorithm](https://dkolmas.github.io/blog/2017/11/09/Foundation-of-backpropagation)\n",
    " * [Softmax and cross-entropy functions in backpropagation algorithm](https://dkolmas.github.io/blog/2017/12/11/Softmax-function-and-cross-entropy-in-backpropagation-algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture of Neural Netowork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Neural Network (NN) architecture is very simple in presented use case. It contains input layer, one hidden layer and output layer:\n",
    "* there are 2 inputs in input layer\n",
    "* there are 100 nodes in hidden layer\n",
    "* there are 3 outputs in output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of inputs (2) and outputs (3) is dictated by a type of data I have used. Details on  data type will be discussed in **Data Samples** section. 100 nodes in hidden layer is arbitrary choosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
